{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc24a4d7-3c26-4855-aafb-f089757c5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polars\n",
      "  Downloading polars-1.29.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Downloading polars-1.29.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars\n",
      "Successfully installed polars-1.29.0\n"
     ]
    }
   ],
   "source": [
    "!pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46f66c2-0b71-4842-8281-8dc183a12888",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "airport_fee\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'sink' <---\n WITH_COLUMNS:\n [\"2023-02\".alias(\"month\")] \n  Parquet SCAN [https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet]\n  PROJECT */19 COLUMNS",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mColumnNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     32\u001b[39m yellow_trip_data = pl.concat(\n\u001b[32m     33\u001b[39m     [\n\u001b[32m     34\u001b[39m         pl.scan_parquet(\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mvertical\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     43\u001b[39m )\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Calculate duration in minutes using native datetime operations\u001b[39;00m\n\u001b[32m     46\u001b[39m yellow_trip_data = \u001b[43myellow_trip_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtpep_dropoff_datetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtpep_pickup_datetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m60\u001b[39;49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.12/site-packages/polars/_utils/deprecation.py:93\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.12/site-packages/polars/lazyframe/frame.py:2224\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, _check_order, _eager, **_kwargs)\u001b[39m\n\u001b[32m   2222\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2223\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mColumnNotFoundError\u001b[39m: airport_fee\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'sink' <---\n WITH_COLUMNS:\n [\"2023-02\".alias(\"month\")] \n  Parquet SCAN [https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet]\n  PROJECT */19 COLUMNS"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from functools import partial\n",
    "\n",
    "target_schema = {\n",
    "    \"VendorID\": pl.Int32,\n",
    "    \"tpep_pickup_datetime\": pl.Datetime,\n",
    "    \"tpep_dropoff_datetime\": pl.Datetime,\n",
    "    \"passenger_count\": pl.Float64,\n",
    "    \"trip_distance\": pl.Float64,\n",
    "    \"RatecodeID\": pl.Int32,\n",
    "    \"store_and_fwd_flag\": pl.String,\n",
    "    \"PULocationID\": pl.Int32,\n",
    "    \"DOLocationID\": pl.Int32,\n",
    "    \"payment_type\": pl.Int32,\n",
    "    \"fare_amount\": pl.Float64,\n",
    "    \"extra\": pl.Float64,\n",
    "    \"mta_tax\": pl.Float64,\n",
    "    \"tip_amount\": pl.Float64,\n",
    "    \"tolls_amount\": pl.Float64,\n",
    "    \"improvement_surcharge\": pl.Float64,\n",
    "    \"total_amount\": pl.Float64,\n",
    "    \"congestion_surcharge\": pl.Float64,\n",
    "    \"airport_fee\": pl.Float64,\n",
    "    \"month\": pl.String\n",
    "}\n",
    "\n",
    "\n",
    "year = '2023'\n",
    "months = ['01', '02']\n",
    "\n",
    "# Create LazyFrames for each month with parallel processing\n",
    "yellow_trip_data = pl.concat(\n",
    "    [\n",
    "        pl.scan_parquet(\n",
    "            f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet'\n",
    "        )\n",
    "        .with_columns(month=pl.lit(f'{year}-{month}'))\n",
    "        .cast(target_schema, strict=False)\n",
    "        .drop(\"airport_fee\")\n",
    "        for month in months\n",
    "    ],\n",
    "    how='vertical'\n",
    ")\n",
    "\n",
    "# Calculate duration in minutes using native datetime operations\n",
    "yellow_trip_data = yellow_trip_data.with_columns(\n",
    "    duration=(\n",
    "        (pl.col(\"tpep_dropoff_datetime\") - pl.col(\"tpep_pickup_datetime\")).dt.total_seconds() / 60\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9c39f-fbaa-404c-8861-0b75715e0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_needed = ['tpep_pickup_datetime', 'duration', 'PULocationID', 'DOLocationID']\n",
    "preprocess_data = yellow_trip_data[\"duration\"].clone().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f8720-a584-4ba9-86f3-7369ed185aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Data preparation\n",
    "def preprocess_data(df):\n",
    "    # Extract temporal features\n",
    "    df['hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df['dayofweek'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "    \n",
    "    # One-hot encode locations with first category dropped\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    pickup_encoded = encoder.fit_transform(df[['PULocationID']])\n",
    "    dropoff_encoded = encoder.fit_transform(df[['DOLocationID']])\n",
    "    \n",
    "    # Combine features\n",
    "    temporal_features = df[['hour', 'dayofweek']]\n",
    "    X = np.hstack([temporal_features, pickup_encoded, dropoff_encoded])\n",
    "    \n",
    "    return X, df['duration'].values\n",
    "\n",
    "# Model specification\n",
    "def build_weibull_model(X, y):\n",
    "    with pm.Model() as model:\n",
    "        # Regression coefficients (including intercept)\n",
    "        beta = pm.Normal('beta', mu=0, sigma=1, shape=X.shape[1])\n",
    "        \n",
    "        # Shape parameter (constrained positive)\n",
    "        alpha = pm.HalfNormal('alpha', sigma=1)\n",
    "        \n",
    "        # Linear predictor for scale parameter\n",
    "        log_scale = pm.math.dot(X, beta)\n",
    "        scale = pm.math.exp(log_scale)\n",
    "        \n",
    "        # Weibull likelihood\n",
    "        pm.Weibull('duration', alpha=alpha, beta=scale, observed=y)\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "    # Load your DataFrame (df must contain: pickup_datetime, pickup_location, dropoff_location, duration)\n",
    "    # df = pd.read_csv(...)\n",
    "    \n",
    "    # X, y = preprocess_data(df)\n",
    "    \n",
    "    # Build and sample model\n",
    "    # model = build_weibull_model(X, y)\n",
    "    # with model:\n",
    "    #     trace = pm.sample(2000, tune=1000, target_accept=0.95)\n",
    "    \n",
    "    # Analyze results\n",
    "    # print(az.summary(trace, var_names=['beta', 'alpha']))\n",
    "    # pm.plot_trace(trace, var_names=['beta', 'alpha'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
